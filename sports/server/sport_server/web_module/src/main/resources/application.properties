#redis
spring.redis.database=3
spring.redis.nodes=localhost:6379
spring.redis.password=
spring.redis.shiro.timeout=1000

spring.data.mongodb.auto-index-creation=true
spring.data.mongodb.uri=mongodb://localhost:27017/sport-mongodb?replicaSet=rs0
spring.jpa.open-in-view=false
server.port=8009

#============== kafka ===================
spring.kafka.bootstrap-servers=localhost:9092

#=============== provider  =======================
#设置大于0的值，则客户端会将发送失败的记录重新发送
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
# 指定消息key和消息体的编解码方式 UTF-8
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=queue-consumer-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100
# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer


data.upload.file.depth=2
local.domain.url=http://192.168.0.113:9011
#Fastdfs
fdfs.so-timeout=1500
fdfs.connect-timeout=600
fdfs.pool.max-wait-millis=5000
fdfs.pool.max-total-per-key=50
fdfs.pool.max-idle-per-key=10
fdfs.pool.min_idle_per_key=5
fdfs.thumb-image.width=150
fdfs.thumb-image.height=150
fdfs.tracker-list=52.128.228.82:22122
fdfs.web-server-url=http://${WEB_SERVER_URL:localhost}:${WEB_PORT:8010}/
spring.servlet.multipart.max-file-size=500MB